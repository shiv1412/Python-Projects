{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([3, 3, 3, 3, 7, 1, 8, 4, 5, 7])]\n",
      "tensor(3)\n",
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.871666666666666%\n",
      "1: 11.236666666666666%\n",
      "2: 9.93%\n",
      "3: 10.218333333333334%\n",
      "4: 9.736666666666666%\n",
      "5: 9.035%\n",
      "6: 9.863333333333333%\n",
      "7: 10.441666666666666%\n",
      "8: 9.751666666666667%\n",
      "9: 9.915000000000001%\n",
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "tensor(0.0737, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1792, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1000, grad_fn=<NllLossBackward>)\n",
      "Accuracy : 0.978\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size = 10, shuffle= True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size = 10, shuffle= True)\n",
    "for data in trainset:\n",
    "    print(data)\n",
    "    break;\n",
    "x,y = data[0][0],data[1][0]\n",
    "print(y)\n",
    "import matplotlib.pyplot as plt \n",
    "print(data[0][0].shape)\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()\n",
    "total = 0 \n",
    "counter_dict = {}\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "\n",
    "print(counter_dict)\n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100.0}%\")\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        # with multiclass softmax works\n",
    "        return F.log_softmax(x, dim =1)      \n",
    "        \n",
    "net = Net()\n",
    "print(net)\n",
    "        \n",
    "import torch\n",
    "X = torch.rand((28*28))\n",
    "X\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr= 0.001)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(3):\n",
    "    for data in trainset:\n",
    "        X,y = data \n",
    "        net.zero_grad()\n",
    "        output =net(X.view(-1,28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "        \n",
    "correct = 0\n",
    "total = 0 \n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X,y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuracy :\" , round(correct/total, 3))\n",
    "             \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()\n",
    "\n",
    "print(torch.argmax(net(X[3].view(-1,784))[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.2.0.32-cp37-cp37m-win_amd64.whl (33.0 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in d:\\anaconda\\lib\\site-packages (from opencv-python) (1.16.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.2.0.32\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "REBUILD_DATA = True\n",
    "\n",
    "class DogsVSCats():\n",
    "    IMG_SIZE =50\n",
    "    CATS = \"D:/Machine Learning/kagglecatsanddogs_3367a/PetImages/Cat\"\n",
    "    DOGS = \"D:/Machine Learning/kagglecatsanddogs_3367a/PetImages/Dog\"\n",
    "    LABELS = {CATS:0 , DOGS: 1}\n",
    "    \n",
    "    training_data = []\n",
    "    cat_count = 0\n",
    "    dog_count = 0\n",
    "    \n",
    "    \n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                try:\n",
    "                    path =os.path.join(label,f)\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img = cv2.resize(img, (self.IMG_SIZE,self.IMG_SIZE))\n",
    "                    self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]] ])\n",
    "                \n",
    "                    if label == self.CATS:\n",
    "                        self.catcount += 1\n",
    "                    elif label == self.DOGS:\n",
    "                        self.dogcount += 1\n",
    "                except Exception as e:\n",
    "                    pass \n",
    "            \n",
    "            \n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print(\"Cats:\",self.cat_count)\n",
    "        print(\"Dogs:\",self.dog_count)\n",
    "                      \n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()\n",
    "         \n",
    "            \n",
    "training_data = np.load(\"training_data.npy\",allow_pickle = True)\n",
    "print(len(training_data))\n",
    "\n",
    "print (training_data[1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_data[1][0],cmap = \"gray\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
