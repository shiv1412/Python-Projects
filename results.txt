Spark context available as 'sc' (master = local[*], app id = local-1589149903409).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.5
      /_/

 

Using Scala version 2.11.12 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_251)
Type in expressions to have them evaluated.
Type :help for more information.

 

scala> import org.apache.spark.SparkContext
import org.apache.spark.SparkContext

 

scala> import org.apache.spark.SparkContext._
import org.apache.spark.SparkContext._

 

scala> val txtFile = "README.md"
txtFile: String = README.md

 

scala> val txtData = sc.textFile(txtFile)
txtData: org.apache.spark.rdd.RDD[String] = README.md MapPartitionsRDD[1] at textFile at <console>:30

 

scala> txtData.cache()
res0: txtData.type = README.md MapPartitionsRDD[1] at textFile at <console>:30

 

scala> txtData.count()
res1: Long = 104

 

scala> val wcData = txtData.flatMap(l => l.split(" ")).map(word => (word, 1)).reduceByKey(_ + _)
wcData: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at <console>:29

 

scala> wcData.collect().foreach(println)
(package,1)
(this,1)
(integration,1)
(Python,2)
(page](http://spark.apache.org/documentation.html).,1)
(cluster.,1)
(its,1)
([run,1)
(There,1)
(general,3)
(have,1)
(pre-built,1)
(Because,1)
(locally.,1)
(locally,2)
(changed,1)
(sc.parallelize(1,1)
(only,1)
(several,1)
(This,2)
(basic,1)
(Configuration,1)
(learning,,1)
(documentation,3)
(YARN,,1)
(graph,1)
(Hive,2)
(info,1)
(["Specifying,1)
("yarn",1)
([params]`.,1)
(first,1)
([project,1)
(prefer,1)
(SparkPi,2)
(<http://spark.apache.org/>,1)
(engine,1)
(version,1)
(file,1)
(documentation,,1)
(MASTER,1)
(example,3)
(are,1)
(systems.,1)
(params,1)
(scala>,1)
(DataFrames,,1)
(provides,1)
(refer,2)
(configure,1)
(Interactive,2)
(R,,1)
(can,6)
(build,3)
(when,1)
(easiest,1)
(Apache,1)
(how,3)
(package.,1)
(1000).count(),1)
(Note,1)
(Data.,1)
(>>>,1)
(Scala,2)
(Alternatively,,1)
(tips,,1)
(variable,1)
(submit,1)
(Testing,1)
(Streaming,1)
(module,,1)
(Developer,1)
(test,,1)
(Version,1)
(thread,,1)
(rich,1)
(them,,1)
(detailed,2)
(stream,1)
(GraphX,1)
(distribution,1)
(review,1)
(Please,4)
(return,2)
(is,7)
(Thriftserver,1)
(same,1)
(start,1)
(built,1)
(one,2)
(with,3)
(Spark](#building-spark).,1)
(Spark"](http://spark.apache.org/docs/latest/building-spark.html).,1)
(data,1)
(Kubernetes,1)
(Contributing,1)
(using,3)
(talk,1)
(Shell,2)
(class,2)
(Enabling,1)
(Tools"](http://spark.apache.org/developer-tools.html).,1)
(README,1)
(computing,1)
(Python,,2)
(example:,1)
(##,9)
(from,1)
(set,2)
(building,2)
(N,1)
(Hadoop-supported,1)
(other,1)
(Example,1)
(analysis.,1)
(runs.,1)
(Building,1)
(higher-level,1)
(need,1)
(Big,1)
(fast,1)
(guide,,1)
(Java,,1)
(<class>,1)
(uses,1)
(SQL,2)
(will,1)
(information,1)
(IDE,,1)
(requires,1)
(get,1)
(,72)
(guidance,2)
(YARN"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn),1)
(Documentation,1)
(web,1)
(cluster,2)
(using:,1)
(MLlib,1)
(contributing,1)
(shell:,2)
(Scala,,1)
(supports,2)
(built,,1)
(tests](http://spark.apache.org/developer-tools.html#individual-tests).,1)
(./dev/run-tests,1)
(build/mvn,1)
(sample,1)
(For,3)
(Programs,1)
(Spark,15)
(particular,2)
(The,1)
(processing.,1)
(APIs,1)
(computation,1)
(Try,1)
([Configuration,1)
(./bin/pyspark,1)
(A,1)
(through,1)
(#,1)
(library,1)
(following,2)
(More,1)
(which,2)
(also,5)
(storage,1)
(should,2)
(To,2)
(for,12)
(Once,1)
(["Useful,1)
(setup,1)
(mesos://,1)
(Maven](http://maven.apache.org/).,1)
(latest,1)
(processing,,1)
(the,23)
(your,1)
(not,1)
(different,1)
(distributions.,1)
(given.,1)
(About,1)
(if,4)
(instructions.,1)
(be,2)
(do,2)
(Tests,1)
(no,1)
(project.,1)
(./bin/run-example,2)
(programs,,1)
(including,4)
(`./bin/run-example,1)
(Spark.,1)
(Versions,1)
(started,1)
(HDFS,1)
(individual,1)
(spark://,1)
(It,2)
(an,4)
(programming,1)
(machine,1)
(run:,1)
(environment,1)
(clean,1)
(1000:,2)
(And,1)
(guide](http://spark.apache.org/contributing.html),1)
(developing,1)
(run,7)
(./bin/spark-shell,1)
(URL,,1)
("local",1)
(MASTER=spark://host:7077,1)
(on,7)
(You,3)
(threads.,1)
(against,1)
([Apache,1)
(help,1)
(print,1)
(tests,2)
(examples,2)
(at,2)
(in,5)
(-DskipTests,1)
(optimized,1)
(development,1)
(downloaded,1)
(graphs,1)
(Guide](http://spark.apache.org/docs/latest/configuration.html),1)
(versions,1)
(usage,1)
(online,1)
(abbreviated,1)
(comes,1)
(directory.,1)
(overview,1)
([building,1)
(`examples`,2)
(Many,1)
(Running,1)
(way,1)
(use,3)
(Online,1)
(site,,1)
(running,1)
([Contribution,1)
(find,1)
(sc.parallelize(range(1000)).count(),1)
(contains,1)
(project,1)
(you,4)
(Pi,1)
(that,2)
(protocols,1)
(a,9)
(or,3)
(high-level,1)
(name,1)
(Hadoop,,2)
(to,17)
(available,1)
((You,1)
(core,1)
(instance:,1)
(see,3)
(of,5)
(tools,1)
(resource-managers/kubernetes/integration-tests/README.md,1)
("local[N]",1)
(programs,2)
(package.),1)
(["Building,1)
(must,1)
(and,10)
(command,,2)
(system,1)
(Hadoop,3)